MPI

```C
int MPI_Bcast(
	void*         data_p       // in/out
	int           count        // in
	MPI_Datatype  datatype     //in
	int           source_proc  //in
	MPI_Comm      comm
)
```

- sia input che output:
	- per il rank `0` sarà un parametro di output, per tutti gli altri di input (rank 0 fornisce un valore, gli altri si trovano i dati in `data_p`)

- more readable (it's obvious that it's a broadcast)

### MPI_Allreduce 
Conceptually an `MPI_Reduce` followed by an `MPI_Bcast`.


- the argument list is identical to that of `MPI_Reduce`, but there is no `dest_process` since all the processes will get the results

In molti casi l'algoritmo non 



### Elapsed parallel time
```C
double MPI_Wtime(void);
```

rturns the # of seconds that have elapsed since ?? in the past

>[!question] measuring
> What time do we consider when we have to calculate how much time a program takes? Each rank might finish at different times.


>[!question] is every rank going to start at the same time?
> not necessarily.
> se non partono insieme, un processo ci puo' mettere piu' tempo per esempio per aspettare (receive) (la send di) un altro processo che e' partito dopo

Per far si' che i processi inizino qualcosa allo stesso tempo, si puo' usare una `MPI_Barrier` (ma comunque potrebbero uscire dalla barriera in tempi diversi).

(I tempi non sono deterministici) ⟶ **noise**

Examples:
- se lancio un'applicazione sul mio portatile, ci sono altri processi che stanno essendo eseguiti - in base alle decisioni dello scheduler, i tempi saranno diversi 
- le risorse di calcolo sono separate ma la rete di calcolo e' condivisa, quindi altre applicazioni potrebbero utilizzarla (es. due processi fanno una send x due processi di 2 utenti diversi, che pero' attraversano lo stesso link fisico della rete)
- 