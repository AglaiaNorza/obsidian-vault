I core devono comunicare

Memoria condivisa o memoria distribuita

![[parallel-systems.png|center|450]]

Due tipi di sistemi paralleli
- **multiple-instruction multiple-data** (MIMD)
	- ogni core esegue un'istruzione diversa
	- es. CPU

- **single inst** (processori vettoriali)
	- ogni core esegue la stessa istruzione su un pezzo di dato diverso
	- es. GPU


|          | shared memory            | distributed memory |
| -------- | ------------------------ | ------------------ |
| **SIMD** | CUDA                     |                    |
| **MIMD** | Pthreads / OpenMP / CUDA | MPI                |

## concurrent vs parallel vs distributed
- **concurrent** ⟶ in ciascuno momento, ci possono essere + task attive (possono essere tutte indipendenti una dall'altra) (es. vari processi)
- **parallel** ⟶ multiple tasks cooperate closely to solve a problem
- **distributed** ⟶ the cooperation is more sporadic 

Parallel and distributed are concurrent

Concurrent programs can be serial
